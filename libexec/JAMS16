#!/usr/bin/env Rscript
suppressMessages(suppressPackageStartupMessages(library(optparse)))

#####################################
# Define System-specific Functions ##
#####################################
if ((.Platform$OS.type) != "unix"){
    stop("JAMS only works on UNIX. Install Linux and try again.")
}

#Get slurm job ID
slurmjobid <- as.character(Sys.getenv("SLURM_JOB_ID"))

#Decide which kind of system you are on.
if(nchar(slurmjobid) < 3){
    cat("You are not on a Slurm Workload Cluster\n")
} else {
    cat(paste("You are on a Slurm Workload Manager Cluster under jobID", slurmjobid, "\n"))
}

#################
## Get options ##
#################

option_list <- list(
    make_option(c("-p", "--projectname"),
                action="store", default = "MyProject",
                type="character",
                help="Name of project to be used as prefix for output files (required)"),

    make_option(c("-o", "--outdir"),
                action="store", default = getwd(),
                type="character",
                help ="path to where you want the output."),

    make_option(c("-x", "--excel_metadata"),
                action="store", default = NULL,
                type="character",
                help="Metadata file in Excel format, with sheet_1 for phenotable and sheet_2 for phenolabels"),

    make_option(c("-t", "--phenotable_tsv"),
                action="store", default = NULL,
                type="character",
                help="Metadata file in tsv format, with headers"),

    make_option(c("-l", "--phenolabels_tsv"),
                action="store", default = NULL,
                type="character",
                help="Phenolabels file in tsv format, describing metadata file headers"),

    make_option(c("-c", "--maxnumclasses"),
                action="store", default = 15,
                type="numeric",
                help="Maximum number of classes for a discrete variable to be kept. Default=15"),

    make_option(c("-i", "--class_to_ignore"),
                action="store", default = "N_A",
                type="character",
                help="Ignore cells containing this text in the metadata. Samples bearing this class of text when comparing within a variable will be omitted from an analysis. Default = N_A"),

    make_option(c("-y", "--reads_files_path"),
                action="store", default = NULL,
                type="character",
                help ="path to where all fastq files are"),

    make_option(c("-b", "--basespace_projectID"), default = NULL, action="store",
                help = str_c("Project ID for downloading reads from Illumina BaseSpace. If using the -b option, any reads from the -y input will be ignored. BaseSpace CLI must be installed. To install, see this: https://developer.basespace.illumina.com/docs/content/documentation/cli/cli-overview")),

    make_option(c("-T", "--trunclen_cutoffs_R1_R2"),
                action="store", default = "240,200",
                type="character",
                help ="Specify truncation lengths for R1,R2 (example: -T 240,200). If not specified, JAMS16 will impute appropriate values for truncation with fastq quality analysis."),

    make_option(c("-a", "--taxonomy_database"),
                action="store", default = NULL,
                type="character",
                help ="path to the taxonomy database."),

    make_option(c("-e", "--export_tables"),
                action="store_true", default = FALSE,
                type="logical",
                help ="Export relative abundance tables and feature data tables in tsv format."),

    make_option(c("-d", "--make_ordination_reports"),
                action="store", default = NULL,
                type="character",
                help ="Generate ordination plots with this algorithm. Choose between PCA, tSNE or tUMAP, or more than one separated by a comma. Example: -d PCA,tUMAP"),

    make_option(c("-f", "--make_exploratory_reports"),
                action="store_true", default = FALSE,
                type="logical",
                help ="Generate Relative Abundace heatmaps and spreadsheets based on variance analysis."),

    make_option(c("-k", "--make_comparative_reports"),
                action="store_true", default = FALSE,
                type="logical",
                help ="Generate Relative Abundace heatmaps and spreadsheets for hypothesis testing using metadata categories."),

    make_option(c("-r", "--make_correlation_reports"),
                action="store_true", default = FALSE,
                type="logical",
                help ="Generate Pairwise Feature Correlation heatmaps."),

    make_option(c("-z", "--make_alpha_reports"),
                action = "store_true", default = FALSE,
                type = "logical",
                help = "Generate alpha diversity plots."),

    make_option(c("-m", "--plot_in_parallel"),
                action = "store_true", default = FALSE,
                type = "logical",
                help = "Use multiple CPUs when generating plots. This option is experimental, and is not guaranteed to not crash."),

    make_option(c("-s", "--run_script"),
                action="store", default = NULL,
                type="character",
                help ="Path to an R script to run after all other options have been executed. Example: -s /path/to/make_these_specific_plots.R will execute the commands in this script at the end of JAMSbeta."),

    make_option(c("-Q", "--plot_read_qualities"),
                action = "store_true", default = TRUE,
                type = "logical",
                help = "Plot read qualities to PDF file. Default is to not plot."),

    make_option(c("-v", "--version"),
                action="store_true", help = "report version")
 )

# get the cmd line options to the script
args <- commandArgs(trailingOnly = TRUE)

# parse the options
opt <- parse_args(OptionParser(option_list = option_list), args)

#Add version from package to opt
opt$verstr <- paste0("JAMS v", packageVersion("JAMS"))

# print version & exit if -v
if (!is.null(opt$version)) {
    print(opt$verstr)
    quit()
}

#Load flogger package
#suppressMessages(suppressPackageStartupMessages(library(futile.logger)))

#Authorship message
authors <- as.character(as.person(packageDescription("JAMS")$Author))
authorshipmessage <- c(packageDescription("JAMS")$Title, paste("JAMS version", packageVersion("JAMS")), authors, paste("Contact:", "john.mcculloch@nih.gov"), "National Cancer Institute", "National Institutes of Health", "Bethesda, MD, USA")

#Fix path relativity
fixrelpath <- function(JAMSpath = NULL){
    require(R.utils)
    if (!(isAbsolutePath(JAMSpath))){
        fixedpath <- getAbsolutePath(JAMSpath)
    } else {
        fixedpath <- JAMSpath
    }
    #Chomp a "/" from the end of paths
    fixedpath <- gsub("/$", "", fixedpath)

    return(fixedpath)
}

for (pathtofix in c("outdir", "excel_metadata", "phenotable_tsv", "phenolabels_tsv", "reads_files_path", "taxonomy_database", "run_script")){
    if (!is.null(opt[[pathtofix]])){
        opt[[pathtofix]] <- fixrelpath(opt[[pathtofix]])
    }
}

if (!is.null(opt$run_script)){
    #Check that file exists
    if (!file.exists(opt$run_script)){
        flog.info(paste("Unable to find file", opt$run_script))
        q()
    }
}

# Determine output directory
if (!is.null(opt$outdir)) {
    if (!file.exists(opt$outdir)){
        dir.create(opt$outdir, recursive = TRUE)
    }
    setwd(opt$outdir)
} else {
    opt$outdir <- getwd()
}


# give help if needed input option not provided
#if (is.null(opt$reads_files_path)) {
#    parse_args(OptionParser(option_list = option_list), c("-h"))
#    stop("You must supply fastq files with the -r option to build experiments.")
#}

#Set defaults
asPA <- FALSE
opt$projimage <- file.path(opt$outdir, ".RData")

###################
## Start project ##
###################
suppressMessages(suppressPackageStartupMessages(library(JAMS)))
if (TRUE){
    opt$logfile <- file.path(opt$outdir, paste0(opt$projectname, "_JAMS.log"))
    flog.appender(appender.tee(opt$logfile))
}

flog.info("JAMS - Just A Microbiology System")
flog.info(authorshipmessage)

flog.info("JAMS16 start. Gathering information...")
project <- as.character(opt$projectname)
flog.info(paste("Using", project, "for name of project"))

opt$threads <- as.numeric(detectHardwareResources()["threads"])
flog.info(paste("You have", opt$threads, "CPUs available."))

opt$silva_trainset <- sort(file.path(opt$taxonomy_database, list.files(path = opt$taxonomy_database, pattern = "train")))[1]
opt$silva_species_assignment <- sort(file.path(opt$taxonomy_database, list.files(path = opt$taxonomy_database, pattern = "species")))[1]

flog.info(paste("Content will be output to", opt$outdir))

##################
## Get metadata ##
##################

###
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

#Get metadata
opt <- load_metadata_from_file(opt = opt)

#Stop if something went wrong
if ((is.null(opt$phenotable)) || (nrow(opt$phenotable) < 1)){
    stop("No data found in the metadata file supplied. Please check file.")
} else {
    flog.info(paste("Metadata has", ncol(opt$phenotable), "columns."))
}

##########
## Will keep this running in all cases. Not sure of the consequences for when loading a workspace and NOT changing metadata.
opt$metadatavetting <- TRUE

if (opt$metadatavetting == TRUE){
    #If phenolabels exists, make sure that phenotable contains only data described in phenolabels.
    if (!is.null(opt$phenolabels)){
        if (!all(colnames(opt$phenolabels) %in% c("Var_label", "Var_type"))) {
            stop("Could not find the Var_label and/or Var_type columns in phenolabels table. Consult documentation and check metadata file(s).")
        }

        validcols <- as.character(opt$phenolabels$Var_label)
        flog.info(paste("Phenolabels contains", length(validcols), "categories."))

        #Stop if you are asking for more than you have.
        if (length(validcols) > ncol(opt$phenotable)){
            stop("Phenolabels has more categories than the metadata in phenotable. Review and try again.")
        }

        ptsampcol <- as.character(opt$phenolabels$Var_label[which(opt$phenolabels$Var_type == "Sample")])
        if (length(ptsampcol) != 1){
             stop("You must define exactly one column as being the Sample column in your metadata. Please see documenation.")
        } else {
             flog.info(paste("Samples are in the", ptsampcol, "column in the metadata."))
        }

        flog.info(paste("Metadata classes specified in phenolabels are:", paste0(validcols, collapse = ", ")))
        flog.info("Adjusting metadata to contain only these columns.")

        #Stop if the classes you want in phenolabels do not exist in phenotable.
        if (all(validcols %in% colnames(opt$phenotable))){
            opt$phenotable <- opt$phenotable[ , validcols]
        } else {
            stop("One or more classes specified in phenolabels is missing as (a) column(s) in phenotable. Please check files.")
        }

    } else {
        #No phenolabels, so try and find at least a Sample column in the metadata.
        flog.info("Phenolabels not found. Will attempt to find which column is the Sample data.")
        ptsampcol <- colnames(opt$phenotable)[which(colnames(opt$phenotable) %in% c("Sample", "sample"))]
        if (length(ptsampcol) != 1){
            stop("You must define exactly one column as being the Sample column in your metadata. Please see documenation.")
        }
    }

    #Stop if something went wrong after subsetting phenotable to desired columns in phenolabels.
    if (nrow(opt$phenotable) < 1){
        stop("No data found in the metadata file supplied. Please check file.")
    }
}

#Save in case anything else goes wrong later
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

#Download BaseSpace reads, if required
if (!is.null(opt$basespace_projectID)){
    flog.info(paste("Downloading reads from BasesSpace under project ID", as.character(opt$basespace_projectID)))
    opt$reads_files_path <- file.path(opt$outdir, "BaseSpaceReads")
    dir.create(opt$reads_files_path, recursive = TRUE)
    cmd <- paste("bs", "download", "project", "-i", as.character(opt$basespace_projectID), "-o", opt$reads_files_path)
    system(cmd)
}

Samples_want <- as.character(opt$phenotable[ , ptsampcol])
#Look for corresponding fastqs with the wanted sample prefixes
#Get a list of fastq files
rawfastqpaths <- list.files(path = opt$reads_files_path, pattern = "fastq.gz", full.names = TRUE, recursive = TRUE)
rawfastqnames <- sapply(1:length(rawfastqpaths), function(x) { tail(unlist(strsplit(rawfastqpaths[x], split = "/")), n = 1) })
rawfastqsdf <- data.frame(Filenames = rawfastqnames, Filepaths = rawfastqpaths, stringsAsFactors = FALSE)
rawfastqsdf$Read <- sapply(1:nrow(rawfastqsdf), function(x) { analyze_fastq_filename(fn=rawfastqsdf$Filenames[x])$Read } )
rawfastqsdf$Lane <- sapply(1:nrow(rawfastqsdf), function(x) { analyze_fastq_filename(fn=rawfastqsdf$Filenames[x])$Lane } )
rawfastqsdf$OriPrefix <- sapply(1:nrow(rawfastqsdf), function(x) { analyze_fastq_filename(fn=rawfastqsdf$Filenames[x])$OriPrefix } )

#Subset them to wanted samples from metadata
Samples_have <- intersect(unique(rawfastqsdf$OriPrefix), unique(Samples_want))
#Report if anything is MISSING
if (length(Samples_have) < length(Samples_want)){
    flog.warn(paste("Fastq files for", (length(Samples_want) - length(Samples_have)), "of the samples on the metadata were not found in", opt$reads_files_path))
    flog.warn(paste("MISSING:", paste0(Samples_want[!(Samples_want %in% Samples_have)], collapse = ", ")))
    flog.warn("Check your metadata and fastq file path!")
}

#Subset fastqs to only the ones wanted from the metadata
rawfastqsdf <- subset(rawfastqsdf, OriPrefix %in% Samples_have)

#Check forward and reverse for each sample
Samples_have_R1R2 <- intersect(subset(rawfastqsdf, Read == "R1")[]$OriPrefix, subset(rawfastqsdf, Read == "R2")[]$OriPrefix)

if (length(Samples_have_R1R2) < length(Samples_have)){
    flog.warn(paste("Sample(s)", paste0(Samples_have[!(Samples_have %in% Samples_have_R1R2)], collapse = ", "), "is MISSING a file for one of the reads."))
    flog.warn("Check your metadata and fastq file path!")
}
rawfastqsdf <- subset(rawfastqsdf, OriPrefix %in% Samples_have_R1R2)

#Are there at least two samples?
if (nrow(rawfastqsdf) < 3){
    flog.warn(paste("There are only", nrow(rawfastqsdf), "samples that were found in the fastq file path. Check your metadata and fastq file path! Aborting now."))
    q()
}
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

#Check each sample has two files
if (length(Samples_have_R1R2) != (nrow(rawfastqsdf) / 2)){
    flog.warn("Some samples have more than two fastq files. Check your metadata and fastq file path! Aborting now.")
    q()
}
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

phredcutoff <- 18

if (is.null(opt$trunclen_cutoffs_R1_R2)){

    require("Rqc")
    flog.info("Analyzing read qualities")
    #Deal with the "all connections are in use" open by doing them in batches
    quality_list <- list()
    filelist <- split(1:length(rawfastqsdf$Filepaths), ceiling(seq_along(1:length(rawfastqsdf$Filepaths)) / 50))
    for (fls in 1:length(filelist)){
        quality_list_tmp <- suppressWarnings(Rqc::rqcQA(rawfastqsdf$Filepaths[filelist[[fls]]], workers = max((opt$threads - 2), 1)))
        quality_list <- c(quality_list, quality_list_tmp)
    }

    flog.info("Determining the best truncation length for reads")
    find_phred_cutoff <- function(qa = NULL, SampName = NULL){
        CyclePhreddf <- rqcCycleAverageQualityCalc(qa[[SampName]])
        CyclePhreddf$cycle <- as.numeric(CyclePhreddf$cycle)
        loess_out <- loess(quality ~ cycle, data = CyclePhreddf)
        CyclePhreddf$Fitted <- fitted(loess_out)
        cyclecutoffs <- sapply(10:30, function (x){ CyclePhreddf$cycle[max(which(CyclePhreddf$Fitted >= x))] })
        names(cyclecutoffs) <- paste0("Q", 10:30)

        return(cyclecutoffs)

    }

    CyclePhred_list <- lapply(names(quality_list), function(x){ find_phred_cutoff(qa = quality_list, SampName = x)} )

    names(CyclePhred_list) <- names(quality_list)
    CyclePhreddf_per_Sample <- as.data.frame(bind_rows(CyclePhred_list, .id = "id"))
    colnames(CyclePhreddf_per_Sample)[which(colnames(CyclePhreddf_per_Sample) == "id")] <- "Filenames"
    for (colm in 1:ncol(CyclePhreddf_per_Sample)){
        if (any(is.na(CyclePhreddf_per_Sample[ , colm]))){
            CyclePhreddf_per_Sample[is.na(CyclePhreddf_per_Sample[ , colm]), colm] <- 1
        }
    }

    rawfastqsdf <- left_join(rawfastqsdf, CyclePhreddf_per_Sample, by = "Filenames")
    rownames(rawfastqsdf) <- rawfastqsdf$Filenames

    quantile75cutoff_R1 <- sapply(paste0("Q", 10:30), function(x) { as.numeric(quantile(subset(rawfastqsdf, Read == "R1")[ , x], probs = seq(0, 1, 0.1))["90%"]) })
    quantile75cutoff_R2 <- sapply(paste0("Q", 10:30), function(x) { as.numeric(quantile(subset(rawfastqsdf, Read == "R2")[ , x], probs = seq(0, 1, 0.1))["90%"]) })

    trunclen_cutoffs_R1_R2 <- unname(c(quantile75cutoff_R1[paste0("Q", phredcutoff)], quantile75cutoff_R2[paste0("Q", phredcutoff)]))

    flog.info(paste("For R1 reads, on read cycle", trunclen_cutoffs_R1_R2[1], "the Phred quality is above", phredcutoff, "in the 90th percentile of reads"))
    flog.info(paste("For R2 reads, on read cycle", trunclen_cutoffs_R1_R2[2], "the Phred quality is above", phredcutoff, "in the 90th percentile of reads"))

} else {
    trunclen_cutoffs_R1_R2 <- as.numeric(unlist(strsplit(opt$trunclen_cutoffs_R1_R2, split = ",")))
    flog.info(paste("For R1 reads truncation length will be", trunclen_cutoffs_R1_R2[1], "as specified by the user"))
    flog.info(paste("For R2 reads truncation length will be", trunclen_cutoffs_R1_R2[2], "as specified by the user"))
}

#Flag samples which will not pass quality control
#flagR1_Samples <- rownames(subset(rawfastqsdf, Read == "R1"))[which(subset(rawfastqsdf, Read == "R1")[ , paste0("Q", phredcutoff)] <  trunclen_cutoffs_R1_R2[1])]
#flagR2_Samples <- rownames(subset(rawfastqsdf, Read == "R2"))[which(subset(rawfastqsdf, Read == "R2")[ , paste0("Q", phredcutoff)] <  trunclen_cutoffs_R1_R2[2])]

IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

##########################
## Start dada2 pipeline ##
##########################
#https://benjjneb.github.io/dada2/tutorial_1_8.html

flog.info("Starting dada2 pipeline according to https://benjjneb.github.io/dada2/tutorial_1_8.html")
sample.names <- subset(rawfastqsdf, Read == "R1")[]$OriPrefix

if (opt$plot_read_qualities){
    flog.info("Plotting raw read qualities using dada2")
    pdf(paste(paste(project, "Dada2_Read_Quality_Plots", sep = "_"), "pdf", sep = "."), paper = "a4r")
    for(smp in sample.names){
        print(plotQualityProfile(subset(rawfastqsdf, OriPrefix == smp)[order(subset(rawfastqsdf, OriPrefix == smp)$Read) , c("Filepaths")]))
    }
    dev.off()
}

rawfastqsdf$FilteredFilePaths <- sapply(1:nrow(rawfastqsdf), function(x){ file.path(opt$outdir, "filteredreads", paste0(paste(paste(rawfastqsdf[x , c("OriPrefix", "Read")], collapse = "_"), "filt", sep = "_"), ".fastq.gz")) })

#Be double sure to have the same order always
rawfastqsdfR1 <- subset(rawfastqsdf, Read == "R1")
rownames(rawfastqsdfR1) <- rawfastqsdfR1$OriPrefix
rawfastqsdfR2 <- subset(rawfastqsdf, Read == "R2")
rownames(rawfastqsdfR2) <- rawfastqsdfR2$OriPrefix
rawfastqsdfR2 <- rawfastqsdfR2[rownames(rawfastqsdfR1) , ]

flog.info("Filtering and trimming reads")
out <- filterAndTrim(fwd = rawfastqsdfR1$Filepaths, filt = rawfastqsdfR1$FilteredFilePaths, rev = rawfastqsdfR2$Filepaths, filt.rev = rawfastqsdfR2$FilteredFilePaths, truncLen = trunclen_cutoffs_R1_R2, compress = TRUE, truncQ = 2, maxN = 0, maxEE = c(2,2), rm.phix = TRUE, n = 1e+05, OMP = FALSE, verbose = TRUE, multithread = max((opt$threads - 2), 1))

#Adjust out dataframe
out <- as.data.frame(out)
out$Filenames <- rownames(out)
out <- left_join(out, rawfastqsdf[ , c("Filenames", "OriPrefix")], by = "Filenames")
colnames(out)[1:2] <- c("Number_Reads_Input", "Number_Reads_Output")
out$Filenames <- NULL
rawfastqsdf <- left_join(rawfastqsdf, out, by = "OriPrefix")

#Get a list of reads who do not survive read number threshold
read_count_threshold <- 5000
samplestodiscard <- subset(out, Number_Reads_Output < read_count_threshold)[]$OriPrefix
rawfastqsdf$Sample_Status <- "Sample_Kept_Read_Count_Sufficient"
if (length(samplestodiscard) > 0){
    rawfastqsdf$Sample_Status[which(rawfastqsdf$OriPrefix %in% samplestodiscard)] <- "Sample_Eliminated_Low_Read_Count"
    flog.warn("Samples", paste0(samplestodiscard, collapse = ", "), "were discarded for having less than", read_count_threshold, "reads after filtering.")
    #Reset reads data frame as not containing reads to discard
    rawfastqsdfR1 <- subset(rawfastqsdfR1, !(OriPrefix %in% samplestodiscard))
    rawfastqsdfR2 <- subset(rawfastqsdfR2, !(OriPrefix %in% samplestodiscard))
}

Samples_passing_threshold <- intersect(rawfastqsdfR1$OriPrefix, rawfastqsdfR2$OriPrefix)

rm(out)

filtFs <- rawfastqsdfR1$FilteredFilePaths
filtRs <- rawfastqsdfR2$FilteredFilePaths

sample.names <- rawfastqsdfR1$OriPrefix
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)


flog.info("Learning errors")
errF <- learnErrors(filtFs, multithread = max((opt$threads - 2), 1))
errR <- learnErrors(filtRs, multithread = max((opt$threads - 2), 1))

pdf(paste(paste(project, "Dada2_Error_Rate_Plots", sep = "_"), "pdf", sep = "."), paper = "a4r")
plotErrors(errF, nominalQ=TRUE)
plotErrors(errR, nominalQ=TRUE)
dev.off()
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)


flog.info("Dereplicating reads")
derepFs <- derepFastq(filtFs, verbose = TRUE)
derepRs <- derepFastq(filtRs, verbose = TRUE)
names(derepFs) <- sample.names
names(derepRs) <- sample.names
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)


flog.info("Running dada2 on dereplicated reads")
dadaFs <- dada(derepFs, err = errF, multithread = max((opt$threads - 2), 1))
dadaRs <- dada(derepRs, err = errR, multithread = max((opt$threads - 2), 1))
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

flog.info("Assembling amplicon contigs (\"merging pairs\")")
mergers <- mergePairs(dadaFs, derepFs, dadaRs, derepRs, verbose = TRUE)
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

flog.info("Building counts table")
seqtab <- makeSequenceTable(mergers)
flog.info("Removing chimeras")
seqtab.nochim <- removeBimeraDenovo(seqtab, method = "consensus", multithread = max((opt$threads - 2), 1), verbose = TRUE)
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

getN <- function(x) { sum(getUniques(x)) }
track <- as.data.frame(cbind(sapply(dadaFs, getN), sapply(dadaRs, getN), sapply(mergers, getN), rowSums(seqtab.nochim)))
colnames(track) <- c("DenoisedF", "DenoisedR", "Merged", "NonChim")
track$OriPrefix <- sample.names
rawfastqsdf <- left_join(rawfastqsdf, track, by = "OriPrefix")
flog.info("Exporting read stats")
write.xlsx(rawfastqsdf, file = paste0(opt$projectname, "_Reads_Statistics.xlsx"), col.names = TRUE, row.names = FALSE, colWidths = "auto", borders = "all")

flog.info("Assigning taxonomy down to Genus taxlevel")
taxa <- assignTaxonomy(seqtab.nochim, opt$silva_trainset, multithread = max((opt$threads - 2), 1))
flog.info("Assigning taxonomy down to Species level")
taxa <- addSpecies(taxa, opt$silva_species_assignment)
IO_jams_workspace_image(opt = opt, operation = "save", verbose = FALSE)

flog.info("Building JAMS-style SummarizedExperiment")
#n.b. Pump all these objects into opt to declutter workspace.
opt$tt <- as.data.frame(taxa)
opt$tt$Domain <- opt$tt$Kingdom
opt$tt <- opt$tt[ , c("Domain", "Kingdom", "Phylum", "Class", "Order", "Family", "Genus", "Species")]
taxlvls <- c("Domain", "Kingdom", "Phylum", "Class", "Order", "Family", "Genus")
taxtags <- c("d__", "k__", "p__", "c__", "o__", "f__", "g__")

for(lvl in 1:length(taxlvls)){
    taxlvl <- taxlvls[lvl]
    opt$tt[which(is.na(opt$tt[ , taxlvl]) == FALSE) , taxlvl] <- paste0(taxtags[lvl], opt$tt[which(is.na(opt$tt[ , taxlvl]) == FALSE) , taxlvl])
    opt$tt[which(is.na(opt$tt[ , taxlvl]) == TRUE) , taxlvl] <- "Unclassified"
}

#Add genus-species to species column, like kraken does it so infer_LKT will work as is.
#tt[which(is.na(tt[ , "Species"]) == FALSE) , "Species"] <- paste(tt[which(is.na(tt[ , "Species"]) == FALSE), "Genus"], tt[which(is.na(tt[ , "Species"]) == FALSE) , "Species"], sep = "_")
#tt$Species <- gsub("^g__", "s__", tt$Species)

opt$tt[which(is.na(opt$tt[ , "Species"]) == TRUE) , "Species"] <- "Unclassified"
opt$tt <- infer_LKT(opt$tt)
opt$tt$Species <- opt$tt$LKT
opt$tt$LKT <- make.unique(opt$tt$LKT)

#Get counts table
opt$cts <- t(seqtab.nochim)
opt$cts <- as.data.frame(opt$cts)

#Maintain same order as cts
opt$tt <- opt$tt[rownames(opt$cts), ]

#Create ASV to LKT dictionary
asv2lkt <- data.frame(ASV = rownames(opt$tt), LKT = opt$tt$LKT, stringsAsFactors = FALSE)

#Call ASVs as non-redundant LKTs
rownames(opt$tt) <- opt$tt$LKT
rownames(opt$cts) <- opt$tt$LKT

rownames(opt$phenotable) <- opt$phenotable$Sample
pheno <- opt$phenotable

rownames(pheno) <- pheno$Sample
pheno <- pheno[colnames(opt$cts), ]

variable_list <- define_kinds_of_variables(phenolabels = opt$phenolabels, phenotable = pheno, maxclass = 15, maxsubclass = 4, class_to_ignore = "N_A", verbose = TRUE)

cdict <- make_colour_dictionary(variable_list = variable_list, pheno = pheno, class_to_ignore = "N_A", colour_of_class_to_ignore = "#bcc2c2", colour_table = NULL, shuffle = FALSE)

exp <- make_SummarizedExperiment_from_tables(pheno = pheno, counttable = opt$cts, featuretable = opt$tt, analysisname = "LKT")

metadata(exp)$asv2lkt <- asv2lkt

#######
## Clean up workspace image to reduce RAM footprint

objects_to_clean <- c("dadaFs", "dadaRs", "derepFs", "derepRs", "mergers", "quality_list", "quality_list_tmp", "seqtab", "seqtab.nochim", "taxa", "asv2lkt", "colm", "errF", "errR", "filtFs", "filtRs", "fls")
objects_to_clean <- objects_to_clean[objects_to_clean %in% ls()]
rm(list = objects_to_clean)
gc()

#Save image
IO_jams_workspace_image(opt = opt, operation = "save", verbose = TRUE)

#Stop here and save if nothing else is required.
if (!any(c((!is.null(opt$make_ordination_reports)), (!is.null(opt$run_script)), opt$make_exploratory_reports, opt$make_comparative_reports, opt$make_PA_reports, opt$make_correlation_reports, opt$make_alpha_reports))){
    flog.info("Thank you for using JAMSbeta")
    q()
}

q()
